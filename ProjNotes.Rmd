---
title: "Project Zero"

output: html_document
---


## Project Notes 

This project is concerned with looking at evolutionary signatures of selection on immune-associated genes, both canonical and candidate. All immune genes (canon/noncanon) are based on orthologs from *Apis mellifera* (Amel_HAv3.1, NCBI genome).

Two types of analyses have been previously ran using PAML's module, codeML, using gene product codon alignments consisting of 11 bee species, including *Apis mellifera*. Gene sets are divided into "immunity" and "random", with immunity consisting of "canon" and "non-canon". All alignments consist of 1-1 single-copy orthologs present in all 11 species. Those that did not include all species were dropped.

Evolutionary rate of each gene product was estimated using a codeml run that considers the whole gene product across the given phylogeny as a whole. It is not expected to get dN/dS ratio (omega) values anywhere near 1 (positive selection) using this method as site-specific signals of selection will be likely lost as the ratio is averaged along the length of the product. Instead, this is expected to offer a relative scale of evolutionary rate.

The main analysis consisted of branch-site specific analyses of selection wherein the phylogenetic tree was designated a target, splitting the tree into foreground and background. CodeML then estimates omega value for foreground branches relative to background. For the purposes of this project, each of the designations correspond with the origin or elaboration of social living, to assess if and how these changes in lifestyle affected selection on immune and candidate immune genes in the bees, relative to other genes (the "random" set, which encompass all orthologs that could be made from all proteins in Apis mellifera using the ortholog bash script, OrthoScript [imaginitively named]).

A list of all of the designations and the input newick formats is available in Genome_Misc/tree_designations.txt. I.e.

```{r}
cat(readLines('Genome_Misc/tree_designations.txt', n=2), sep="\n")
```


In the null version of this test, omega ratios on the foreground branches are fixed at 1, with the alternative version starting with omega estimates above 1 (a direct test of positive selection). Each model results in a global maximum log likelihoood score which can then be compared using a LRT.

LRT = (lnLAlt - lnLNull)*2

LRT scores can then be compared to a chi-square distribution with 1 degree of freedom to assess significance. LRT scores above 3.84 are considered significant. 

P-values will be adjusted during this analysis to correct for multiple testing using the Benjamini-Hochburg procedure.

##Setting the Verse

In order to annotate the data with class of gene, description of gene (as it is described in Apis mellifera), etc. we first need a "dataverse" of Amel_HAv3.1.

verseSet.R reads in the relevant information from the Genome_Misc and ImmResources folders.

```{r}
source("Scripts/verseSet.R", local = knitr::knit_global())
```


GeneVerse: created by reading in a file with all genes from Amel HAv3.1 complete with gene product description and transcript ID.

```{r}
head(gene.verse)
```

ImmVerse: created by reading in a file with all immune - associated genes used as the input for the ortholog finding program which created the codon alignments used in the codeML branch-site selection analyses, complete with classifications, transcript, peptide and gene IDs.

```{r}
head(imm.verse)
```

##Immunity Dataset

For each of the 9 origins/elaborations (and episodic versus longterm shift in selection), a results file is produced (using my own batch-PAML running script, BranchSite_Codeml_V2.sh, and the various associated .ctl and tree files). 

Each lnLResults.txt file consists of the name of the gene, the log likelihood score of the null and alternative branch-site models (lnL_Null / lnL_Alt) and the results of the likelihood ratio test ran between them (LRT).

These raw data files look like this.

```{r}
cat(readLines('input/immunity/AllComplex.3.lnLResults.txt', n=5), sep = '\n')
```

###Adding annotations

dataRead_immunity.R will read in the results file, collate them into one source and annotate each gene with descriptions, class of immunity (canon / non-canon) and social origin/elaboration.

```{r}
source("Scripts/dataRead_immunity.R", local = knitr::knit_global())
```

```{r}
head(data[[2]])
```

###Tests of significance

SigTest.R uses the LRT scores and a Chi square distribution (one-tailed, one degree of freedom) to produce pvalues. Pvalues below 0.05 are considered significant (before correction for multiple testing).

To correct for multiple testing, I'll be using the Benjamini-Hochburg procedure.


```{r}
source("Scripts/SigTests.R", local = knitr::knit_global())
```

```{r}
head(data[[3]])
```

How many are still considered significant ? 

```{r}
data.imm <- bind_rows(data)
data.imm$SocOrigin <- as.factor(data.imm$SocOrigin)
data.sig.imm <- filter(data.imm, adj_pvalue < 0.05)
summary(data.sig.imm$SocOrigin)
```

###Write Up

```{r}
write.table(data.imm, "output/CodeML_Results_AllImmune.tsv", quote = F, row.names = F, sep = "\t")
write.table(data.sig.imm, "output/CodeML_SigResults_AllImmune.tsv", quote = F, row.names = F, sep = "\t")
```

##Random Dataset

I'm going to repeat the above, but all at once (using a script, dataReadandTest_random.R).

"Data"" will become a list of the random codeML runs, with it also being saved separated in data.ran.

```{r}
source("Scripts/dataReadandTest_random.R", local = knitr::knit_global())
```

```{r}
head(data[[4]])
```

## Compare Immunity and Random

First off I'm going to combine the random and immune data and put them back into a list of dataframes.

```{r}
data <- rbind(data.imm, data.ran)
write.table(data, "output/CodeML_BranchSiteAnalysis_CompleteResults.tsv", sep="\t", row.names=F, quote=F)

data <- split(data, f = data$SocOrigin)
summary(data[[5]])
```

###Fisher's Exact Test

I will be running a series of Fisher's exact tests (2x2 contingency tables) per social origin: 1 imm versus random, 2 can versus random, 3 noncan versus random, 4 can versus noncan.

Each origin will have its own contingency table per test consisting of a [1,1][1,2],[2,1][2,2] matrix. Colnames are outcomes Selection and No Selection (i.e, significant or not), and the groups are as defined above, in the order defined above. 

For example, CorbSoc test of Can versus Random test will have data input of:

[1,1] = no of can under selection

[2,1] = no of can with no selection (total can - above)

[2,1] = no of random under selection

[2,2] = no of random with no selection (total random - above)

I'll be running a script to achieve the above looking at unadjusted pvalues that are considered significant and spit it out in an object called p.results.

```{r}
source("Scripts/pFisher.R", local = knitr::knit_global())
```

```{r}
p.results
```

A couple of some near significant differences, but no hits otherwise. 

And for the adjusted pvalues ...

```{r}
source("Scripts/adjFisher.R", local = knitr::knit_global())
```

```{r}
adj.results
```

Ha! Lots less significant.

I will have to double check if the Fisher's test is still appropriate now that the size of the random dataset is so much bigger than it was originally.

-- It's not. Sample size is too large. Pearson's Chisq is probably  more apt.

###Pearson's ChiSq with Simulated Pvalues

Using the same contigency tables used above, I will be running ChiSq tests of significance. As in some of these cases the sample frequencies are heavily imbalanced (i.e 5 canonical immune genes under selection versus ~6000 random genes not under selection), I will be simulating the pvalue by Monte Carlo simulation (x10000). 

adjChi.R will run this test and results will appear in the environment in chi.adj.results.

```{r}
source("Scripts/adjChi.R", local = knitr::knit_global())
```

```{r}
chi.adj.results
```

In terms of significant relationships, I think this is a no.

###Bootstrapping Approach

Bootstrapping is a resampling technique to estimate statistics on a population by sampling a dataset with replacement.

A useful feature of the bootstrap method is that the resulting sample of estimations often forms a Gaussian distribution. In additional to summarizing this distribution with a central tendency, measures of variance can be given, such as standard deviation and standard error. Further, a confidence interval can be calculated and used to bound the presented estimate. This is useful when presenting the estimated skill of a machine learning model. (https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)

Sample Size - use a sample size that is the same size as the original dataset. For my purposes, this will be the number of genes under selection (all classes) per origin of sociality tested. The statistic I'm looking for is the number of genes from each class that are then found in each randomly selected dataset. 

i.e. using the CorbSoc origin of sociality ...

```{r}
test <- data[["CorbSoc"]]
nrow(test[test$adj_pvalue < 0.05,])
```

This means I would be making a "population" of all the genes that were tested (this will be very slightly different for each origin of sociality as some branch site analyses for some genes failed in some origins that worked in others, etc) and then sampling 12 genes at random. The number of canon or noncanon genes will be returned, before the genes are replaced and sampling occurs again, x100,000.

From this I should get a distribution with other descriptive statistics including confidence intervals, against which I can then say whether the number of genes of each class under selection differ from what can be expected by chance (by random sampling).

The script has been written so that 100,000 iterations x social origin x class of gene (canon / noncanon) iterations will take place, with results being stored in boot.results. Off to make a cup of tea.

```{r}
source("Scripts/bootstrap.R", local = knitr::knit_global())
```

```{r}
boot.results
```

So, as in the case of the Fisher's test and the Chisq simulated tests, there appears to be no significant relationship between the fact that genes either are or are suspected to be functionally immune and the number of said genes being under selection. The number of genes found to be under selection is no more or less than what you'd expect by chance, as seen after 100000 random sampling iterations.

That took a full 2 hrs to run (tbf it was 18 million iterations in total) and so I need to have this saved asap.

```{r}
write.table(boot.results, "output/BootStrapResults.tsv", row.names = F, quote = F, sep = "\t")
```

##Evolutionary Rate

For the purposes of this part of the analysis I will be using dN/dS ratio (omega) scores as a measure of evolutionary rate. The larger the score, the faster the protein product is considered to be evolving.

For this, codeML considered the alignments and tree topology without any prior designation and so there is no breakdown by origin / elaboration of sociality.

Notes: 

For the omega analysis I have 6091 genes that have had dNdS ratios successfully estimated. Across the branch site analyses I have considered 6109 genes, meaning there are some that will not have a dNdS ratio using this method. 

The following script will read in the raw omega data, remove any duplicates or failed runs and annotate the genes with gene class. Missing genes will be stored in the variable, "omega.miss", erroneous genes will be stored in "omega.erro", results in "omega".

```{r}
source("Scripts/omegaData.R", local = knitr::knit_global())
```

I'm going to combine the genes from the missing and erroneous lists and put it in a text file to re-run through the omega script on the server and see if anything can be saved.

```{r}
omega.rerun <- rbind(omega.miss, omega.error)
omega.rerun
```

```{r}
omega.list <- as.data.frame(omega.rerun$Gene)
write.table(omega.list, "output/missingOmega.txt", row.names = F, col.names = F, quote = F)
```

The missing genes ran and were all recovered. The anomalous gene, LOC724319, continues to give a dNdS ratio of 999 which suggests there may be something wrong with the alignment.

I've renamed the new file with the missing genes added as the input file so will run the script again.

```{r}
source("Scripts/omegaData.R", local = knitr::knit_global())
```


###Visualise.

```{r}
plot(1:nrow(omega), omega$dN.dS, ylab="Omega", pch=21, bg="red")
abline(h=mean(omega$dN.dS), col="blue")
for (i in 1:nrow(omega)) lines(c(i,i), c(mean(omega$dN.dS), omega$dN.dS[i]), col="green")
```

Not very informative when there's this many ...

Try splitting it by class

```{r}
plot(1:nrow(omega), omega$dN.dS, ylab="Omega", xlab="Order", pch=21, bg=as.numeric(omega$Class))
abline(h=mean(omega$dN.dS[omega$Class=="Canon"]))
abline(h=mean(omega$dN.dS[omega$Class=="NonCanon"]), col = "red")
abline(h=mean(omega$dN.dS[omega$Class=="Random"]), col = "blue")
```

Yeah. No.

```{r}
boxplot(dN.dS~Class, data = omega)
```

And just to look at the statistics.

```{r}
mean(omega$dN.dS[omega$Class == "Canon"])
```

```{r}
mean(omega$dN.dS[omega$Class == "NonCanon"])
```

```{r}
mean(omega$dN.dS[omega$Class == "Random"])
```

```{r}
mean(omega$dN.dS)
```

I don't think I need statistical tests to look and see if there's any significant differences, but all the same....

##Tests of Significance

Using Kruskalâ€“Wallis one-way analysis of variance as data is non-parametric. For example ...

```{r}
hist(omega$dN.dS[omega$Class == "NonCanon"], main = "", xlab = "dN.dS")
```

Anyway.

```{r}
require("dplyr")
```

```{r}
group_by(omega, Class) %>%
  summarise(
    count = n(),
    mean = mean(dN.dS, na.rm = T),
    sd = sd(dN.dS, na.rm = T),
    median = median(dN.dS, na.rm = T),
    IQR = IQR(dN.dS, na.rm = T)
  )
```



```{r}
library("ggpubr")
```

```{r}
ggboxplot(omega, x = "Class", y = "dN.dS", 
          color = "Class", palette = c("blue", "green", "orange"),
          order = c("Canon", "NonCanon", "Random"),
          ylab = "Omega", xlab = "Gene Class")
```

```{r}
ggline(omega, x = "Class", y = "dN.dS", 
       add = c("mean_se", "jitter"), 
       order = c("Canon", "NonCanon", "Random"),
       ylab = "Omega", xlab = "Gene Class")
```

And the test ...

```{r}
kruskal.test(dN.dS ~ Class, data = omega)
```

And there we have it. Non significant. All the shock.

